{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types as ptypes\n",
    "import sklearn.decomposition\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations \n",
    "from pathlib import Path\n",
    "base_dir = str(Path().resolve().parent) + '/data/'\n",
    "\n",
    "def scale_series(series, mean, std):\n",
    "    return (series - mean)/std\n",
    "\n",
    "\n",
    "def generate_combination(country_df: pd.DataFrame):\n",
    "\n",
    "    # all contries have full bond and equity market data, so use default combinations\n",
    "    bond_cat_comb = [['Term_Premium'], ['Risk_Premium'], ['Term_Premium', 'Risk_Premium']]\n",
    "    equity_cat_comb = [['Stock_Prices_mom%_change'], ['Stock_Prices_mom24mma%_change'], ['Stock_Market_Volatility'],\n",
    "                    ['Stock_Prices_mom%_change', 'Stock_Prices_mom24mma%_change'],\n",
    "                    ['Stock_Prices_mom%_change', 'Stock_Market_Volatility'],\n",
    "                    ['Stock_Prices_mom24mma%_change', 'Stock_Market_Volatility'],\n",
    "                    ['Stock_Prices_mom%_change', 'Stock_Prices_mom24mma%_change', 'Stock_Market_Volatility']]\n",
    "    \n",
    "    # some countries lost entry in macro fundamental and money and portfolio flow data, \n",
    "    # use set operation to find exist entry in each broad component\n",
    "    macro_cat = set(['REER', 'Current_Account_Balance_change_yryr%', 'Current_Account_Balance_over_GDP',\n",
    "                    'One-Day_Repo_Rate_AVG', 'One-Day_Repo_Rate_EOP',\n",
    "                    'Policy_Rate_&_Fed_Funds_Rate_Differential_AVG', 'Policy_Rate_&_Fed_Funds_Rate_Differential_EOP'])\n",
    "    mpf_cat = set(['Broad_Money_mo12m%_change', 'Velocity_of_Money_mo12m%_change', 'Portfolio_Flows',\n",
    "                    'Foreign_Exchange_Reserve_change_yryr%', 'Foreign_Exchange_Reserve_over_GDP', 'Bank_Lending_mo12m%_change'])\n",
    "    country_df_cols = set(country_df.columns.to_list())\n",
    "    country_macro_cat = macro_cat & country_df_cols\n",
    "    country_mpf_cat = mpf_cat & country_df_cols\n",
    "\n",
    "    # generate combinations for macro fundamental as a list, each combination is a list of column names that in this combination\n",
    "    macro_cat_comb = []\n",
    "    for i in range(len(country_macro_cat)):\n",
    "        comb = combinations(country_macro_cat, i + 1)\n",
    "        for c in comb:\n",
    "            # discard combinations that both have EOP and AVG values\n",
    "            if 'Policy_Rate_&_Fed_Funds_Rate_Differential_EOP' in c and 'Policy_Rate_&_Fed_Funds_Rate_Differential_AVG' in c:\n",
    "                continue\n",
    "            elif 'One-Day_Repo_Rate_EOP' in c and 'One-Day_Repo_Rate_AVG' in c:\n",
    "                continue\n",
    "            macro_cat_comb.append(list(c))\n",
    "    \n",
    "    # same process for money and portfolio flow data\n",
    "    mpf_cat_comb = []\n",
    "    for i in range(len(country_mpf_cat)):\n",
    "        comb = combinations(country_mpf_cat, i + 1)\n",
    "        for c in comb:\n",
    "            mpf_cat_comb.append(list(c))\n",
    "\n",
    "    # cross product all four broad components' combinations to generate full possible combinations of each country\n",
    "    # the full combinations is a list, each entry in list is a list of column names\n",
    "    # the combination can be selected by calling country_df[country_comb[i]]\n",
    "    country_comb = []\n",
    "    for b in bond_cat_comb:\n",
    "        for e in equity_cat_comb:\n",
    "            for m in macro_cat_comb:\n",
    "                for p in mpf_cat_comb:\n",
    "                    country_comb.append(['Date'] + b + e + m + p)\n",
    "    return country_comb\n",
    "\n",
    "def generate_PCA(country_df: pd.DataFrame):\n",
    "    ''' Assert the names and the types of the columns. Assert the cov matrix is all positive. '''\n",
    "    # assert (df.columns[0] == \"Date\")\n",
    "    # assert (ptypes.is_datetime64_dtype(df[\"Date\"]))\n",
    "    assert all(ptypes.is_numeric_dtype(country_df[col]) for col in country_df.columns[1:])\n",
    "    country_df = country_df.dropna(axis = \"index\")\n",
    "    # assert ((df.cov(numeric_only=True).values > 0).all())\n",
    "\n",
    "    ''' Get the date range '''\n",
    "    country_df = country_df.sort_values(by= [\"Date\"], ascending=False, ignore_index=True)\n",
    "    # print(\"The date range is :\", df[\"Date\"].iat[-1], \"to\", df[\"Date\"].iat[0])\n",
    "\n",
    "    # ''' Scale the data '''\n",
    "    # for col in df.columns[1:]:\n",
    "    #     df[col] = scale_series(df[col], df[col].mean(), df[col].std())\n",
    "\n",
    "    ''' Select data frame that ends at 2020-03 '''\n",
    "    end_index = None\n",
    "    for index in range(len(country_df)):\n",
    "        if country_df.iloc[index, 0] == \"2020-03\":\n",
    "            end_index = index\n",
    "            break\n",
    "    assert (end_index is not None)\n",
    "    \n",
    "\n",
    "    ''' Scale the data '''\n",
    "    for col_num in range(1, len(country_df.columns)):\n",
    "        country_df.iloc[:, col_num] = scale_series(country_df.iloc[:, col_num], country_df.iloc[end_index: , col_num ].mean(), country_df.iloc[end_index: , col_num ].std())\n",
    "\n",
    "\n",
    "    df_PCA_decomp = country_df.iloc[end_index:, 1:] ##TODO: 1:\n",
    "    ''' PCA decomposition'''\n",
    "    pca = sklearn.decomposition.PCA(n_components = len(df_PCA_decomp.columns)) \n",
    "    pca.fit(df_PCA_decomp)\n",
    "    df_transformed = pd.DataFrame(np.negative(np.transpose(np.matmul(np.square(pca.components_),np.transpose(country_df.iloc[ :, 1:])))))\n",
    "    # df_transformed = pd.DataFrame(pca.transform(df.iloc[ :, 1:])) ##TODO: 1:\n",
    "    df_transformed.insert(0, \"Date\", country_df[\"Date\"], True)\n",
    "\n",
    "    return pca, df_transformed\n",
    "\n",
    "def dump_result(pca, df_transformed: pd.DataFrame, country):\n",
    "\n",
    "    if country == 'Poland' or country == 'Hungary':\n",
    "        imf_df = pd.read_csv(base_dir + 'IMF_FCI_' + country + '.csv')\n",
    "        df_transformed = df_transformed.merge(imf_df, how = 'left',on =\"Date\")\n",
    "        end_index = None\n",
    "        for index in range(len(df_transformed)):\n",
    "            if df_transformed.iloc[index, 0] == \"2020-03\":\n",
    "                end_index = index\n",
    "                break\n",
    "        assert (end_index is not None)\n",
    "        for col_num in range(1, len(df_transformed.columns)):\n",
    "            df_transformed.iloc[:, col_num] = scale_series(df_transformed.iloc[:, col_num], df_transformed.iloc[end_index: , col_num ].mean(), df_transformed.iloc[end_index: , col_num ].std())\n",
    "        corr_coef = np.corrcoef(df_transformed.iloc[:, 1:].dropna(), rowvar = False)[-1]\n",
    "        df_transformed = df_transformed.sort_values(by= [\"Date\"], ascending=True, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(df_PCA_decomp.columns)):\n",
    "        eigenvector = pca.components_[i]\n",
    "        if (pca.explained_variance_ratio_[i] > 0.3 and ((eigenvector < 0).all() or (eigenvector > 0).all())):\n",
    "            # output the data combination and eigenvector and explained_variance_ratio\n",
    "            decomp_id = str(random.randint(10**9, 10**10 - 1)) # random id\n",
    "            with open(\"./PCA_pipeline/corr/\"+decomp_id+\".txt\", \"w\") as f:\n",
    "                print(\"-\"*20, file = f)\n",
    "                print(\"id\", \":\", decomp_id, file = f)\n",
    "                print(\"corr_coef\", \":\", corr_coef[i], file = f)\n",
    "                print(\"explain variance ratio\", \":\", pca.explained_variance_ratio_[i], file = f)\n",
    "                print(\"Weight\", \":\", file = f)\n",
    "                for name, weight in zip(df_PCA_decomp.columns, eigenvector):\n",
    "                    print(name, \":\", weight, sep = \" \", end = \"\\n\", file = f)\n",
    "                print(\"-\"*20, file = f)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            ## draw figure\n",
    "            \n",
    "            \n",
    "            plt.plot(df_transformed[\"Date\"], df_transformed.iloc[:,1+i], \"-\", color = \"r\", label = \"PCA\")\n",
    "            plt.plot(df_transformed[\"Date\"], df_transformed[\"IMF_FCI\"], \"-\", color = \"g\", label = \"IMF FCI\")\n",
    "            plt.xlabel(\"Date\")\n",
    "            x_major_locator = plt.MultipleLocator(24)\n",
    "            ax = plt.gca()\n",
    "            ax.xaxis.set_major_locator(x_major_locator)\n",
    "            plt.legend(loc = \"best\")\n",
    "            plt.savefig(\"./PCA_pipeline/fig/\"+decomp_id+\".jpg\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    ''' '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv(base_dir + 'Hungary_DataFrame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_comb = generate_combination(country_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = country_df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = country_df.dropna(axis = 1)\n",
    "end_index = country_df[country_df['Date'] == \"2020-03\"].index[0]\n",
    "col_list = country_df.columns.to_list()\n",
    "col_list.remove('Date')\n",
    "\n",
    "''' Scale the data '''\n",
    "for col in col_list:\n",
    "    country_df.loc[:, col] = scale_series(country_df.loc[:, col], country_df.loc[:end_index, col].mean(), country_df.loc[:end_index, col].std())\n",
    "\n",
    "df_PCA_decomp = country_df.loc[:end_index, col_list]\n",
    "''' PCA decomposition'''\n",
    "pca = sklearn.decomposition.PCA(n_components = len(col_list)) \n",
    "pca.fit(df_PCA_decomp)\n",
    "df_transformed = pd.DataFrame(np.negative(np.transpose(np.matmul(np.square(pca.components_),np.transpose(country_df.iloc[ :, 1:])))))\n",
    "# df_transformed = pd.DataFrame(pca.transform(df.iloc[ :, 1:])) ##TODO: 1:\n",
    "df_transformed.insert(0, \"Date\", country_df[\"Date\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_PCA_decomp.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
